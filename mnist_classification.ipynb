{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6b1f52c",
   "metadata": {},
   "source": [
    "## This is a simple Image classification task using MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d651f186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umarsajjad/anaconda3/envs/sklearn_env/lib/python3.10/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# importing the MNIST dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "# fetch_* functions load reaal-life datasets\n",
    "# load_* fucntons load small toy datasets\n",
    "# make_* functions make fake datasets\n",
    "# The generated datasets are returend as (X, y) tuples\n",
    "# The generated datasets contain input data and targets as NumPy arrays\n",
    "# Other datasets are returned as sklearn.utils.Bunch objects\n",
    "# These datasets are dictionaries whose entries can be accessed\n",
    "# The attirbutes for access are: \"DESCR\", \"data\", \"target\"\n",
    "# DESCR: returns the description of the dataset\n",
    "# data: The input data, usually as a 2D NumPy array\n",
    "# target: The labels, usually as 1D numpy array\n",
    "mnist = fetch_openml('mnist_784', as_frame=False)\n",
    "# fetch_openml() returns data as pandas df and labels as pandas series\n",
    "# This is unusual for MNIST dataset which contains images and isnt ideal\n",
    "# To get data as NumPy arrays instead we set \"as_frame=False\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "651821d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's store the data into variables for ease of access\n",
    "X, y = mnist.data, mnist.target\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b1dadf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the shapes of the X (inputs) and y (labels)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f97f6f",
   "metadata": {},
   "source": [
    "* As can seen by the shape of the inputs, there are a total of 70,000 images and each image has 784 features (num pixels-28x28 pixel image)\n",
    "* Each feature can have a value between 0(white) and 255(black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6292daa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's take peak at one example from the dataset\n",
    "# Let's make function that plots the digit\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import random\n",
    "# we are going to use imshow() function of matplotlib to display the image\n",
    "# we use cmap=\"binary\" to get a grayscale color map (0=white, 255=black)\n",
    "\n",
    "def plot_digit(image_data):\n",
    "    image = image_data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "# Let's plot the image\n",
    "\n",
    "digit = X[random.randint(70000)]\n",
    "plot_digit(digit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca0a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
